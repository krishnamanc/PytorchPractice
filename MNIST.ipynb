{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPtl3cqeyoxBDfJ2yRkGUx7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnamanc/PytorchPractice/blob/main/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i4Eb_iDVECzj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to tensors\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with mean and std\n",
        "])"
      ],
      "metadata": {
        "id": "fYX5aabFG5sl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bRqKY0VJUYo",
        "outputId": "a2b48f2c-ea00-49e0-c55e-1dd58cd7ec5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 6279716.56it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1129259.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 10023045.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 13511013.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the split sizes\n",
        "train_size = 55000\n",
        "val_size = 5000\n",
        "\n",
        "# Generate a list of indices and split it into train and validation sets\n",
        "indices = list(range(len(trainset)))\n",
        "train_indices = indices[:train_size]  # First 55,000 indices for training\n",
        "val_indices = indices[train_size:train_size + val_size]  # Next 5,000 indices for validation\n",
        "\n",
        "# Create samplers\n",
        "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)"
      ],
      "metadata": {
        "id": "FviVGYDNIMh_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=False, sampler=train_sampler)\n",
        "val_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=False, sampler=val_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "Ds8MqYpDKoXn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.features = nn.Sequential(\n",
        "        nn.Conv2d(1,16,3,1,1),\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.Conv2d(16,32,3,1,1),\n",
        "        nn.MaxPool2d(2,2),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.BatchNorm2d(32)\n",
        "    )\n",
        "\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(32*7*7,128),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(128,64),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(64,32),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(32,16),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(16,10)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "4kHHXWP3LV2k"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()"
      ],
      "metadata": {
        "id": "DaTFsdPyNvGA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)"
      ],
      "metadata": {
        "id": "U0u_SPMWNy8_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1"
      ],
      "metadata": {
        "id": "mui73ZhLRX7R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The inputs are reshaped using inputs.view(-1, 1, 28, 28) to convert them into the correct 4D format expected by the convolutional layers ([batch_size, channels, height, width]). Adjust the channel dimension (1 in this case) based on your data's actual number of channels. For grayscale images like MNIST, the channel dimension is typically 1. For RGB images, it's 3."
      ],
      "metadata": {
        "id": "9cQQiESkSE8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load(\"model.pth\")"
      ],
      "metadata": {
        "id": "K0i2cDsxY-tZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "uUW9h_hxeVHf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model in training mode explicitly\n",
        "\n",
        "    # Train the model\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.view(-1, 1, 28, 28) # Reshape inputs to [batch_size, channels, height, width]\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HD3fk2XO9sC",
        "outputId": "8ff5eb45-6d06-4d6e-ff4d-80a77203a244"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1, Loss: 0.0209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct, total = 0, 0\n",
        "predictions = []\n",
        "model.eval()\n",
        "\n",
        "for i, data in enumerate(val_loader, 0):\n",
        "  inputs, labels = data\n",
        "  inputs = inputs.view(-1, 1, 28, 28)\n",
        "  outputs = model(inputs)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  predictions.append(outputs)\n",
        "  total += labels.size(0)\n",
        "  correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"Accuracy on validation set : %d %\",(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CqY3zZ1O-s0",
        "outputId": "19f69f2a-73b9-47b1-edac-b252060be4c2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on validation set : %d % 99.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct, total = 0, 0\n",
        "predictions = []\n",
        "model.eval()\n",
        "\n",
        "for i, data in enumerate(test_loader, 0):\n",
        "  inputs, labels = data\n",
        "  inputs = inputs.view(-1, 1, 28, 28)\n",
        "  outputs = model(inputs)\n",
        "  _, predicted = torch.max(outputs.data, 1)\n",
        "  predictions.append(outputs)\n",
        "  total += labels.size(0)\n",
        "  correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\"Accuracy on test set : %d %\",(100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys6eCD2hPuCO",
        "outputId": "11a037a9-0314-41d7-867b-9d013279591e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test set : %d % 99.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(model, 'model6.pth')"
      ],
      "metadata": {
        "id": "dqKDqzoxQBdH"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select a random image from the test dataset\n",
        "random_idx = random.randint(0, len(testset) - 1)\n",
        "random_image, random_label = testset[random_idx]\n",
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    output = model(random_image.unsqueeze(0))  # Add batch dimension\n",
        "\n",
        "# Get the predicted class (assuming it's a classification model)\n",
        "predicted_class = torch.argmax(output, dim=1).item()\n",
        "\n",
        "# Plot the random image using Matplotlib\n",
        "plt.imshow(random_image.squeeze(), cmap='gray')  # Plot the image (remove the batch dimension)\n",
        "plt.title(f'Predicted Class: {predicted_class}, Actual Class: {random_label}')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "PwGfV9xXVDLW",
        "outputId": "660adb78-bde8-4249-c1fb-5743b2e4d5b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchsummary import summary\n",
        "# # Move the model to the GPU if available\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model.to(device)\n",
        "\n",
        "# # Define the input size as a tuple of integers\n",
        "# input_size = (1, 28, 28)  # Assuming input size is (channels, height, width)\n",
        "\n",
        "# # Use torchsummary to print the model summary\n",
        "# summary(model, input_size=input_size)"
      ],
      "metadata": {
        "id": "1hUmBQf6XxDq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZYVLV4DudANp"
      },
      "execution_count": 17,
      "outputs": []
    }
  ]
}